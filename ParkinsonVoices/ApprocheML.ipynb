{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche ML pour Parkinson\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier Excel\n",
    "excel_file = \"Demographics_age_sex.xlsx\"\n",
    "excel_df = pd.read_excel(excel_file, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer chaque fenetre dans des DataFrames différents²\n",
    "df_parselmouth = excel_df['Parselmouth']\n",
    "\n",
    "df_lpcmeans = excel_df['LPC_means']\n",
    "df_larmeans = excel_df['LAR_means']\n",
    "df_cepmeans = excel_df['Cep_means']\n",
    "df_mfccmeans = excel_df['MFCC_means']\n",
    "\n",
    "df_lpcvars = excel_df['LPC_vars']\n",
    "df_larvars = excel_df['LAR_vars']\n",
    "df_cepvars = excel_df['Cep_vars']\n",
    "df_mfccvars = excel_df['MFCC_vars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer les colonnes avec un préfixe pour éviter les répétitions (à voir sur l'excel)\n",
    "df_lpcmeans.columns = ['LPC_means_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_lpcmeans.columns]\n",
    "df_larmeans.columns = ['LAR_means_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_larmeans.columns]\n",
    "df_cepmeans.columns = ['Cep_means_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_cepmeans.columns]\n",
    "df_mfccmeans.columns = ['MFCC_means_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_mfccmeans.columns]\n",
    "\n",
    "df_lpcvars.columns = ['LPC_var_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_lpcvars.columns]\n",
    "df_larvars.columns = ['LAR_var_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_larvars.columns]\n",
    "df_cepvars.columns = ['Cep_var_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_cepvars.columns]\n",
    "df_mfccvars.columns = ['MFCC_var_' + col if col not in ['Sample', 'Label', 'Sex'] else col for col in df_mfccvars.columns]\n",
    "\n",
    "# Combiner les dataframes\n",
    "combined_df1 = pd.concat([df_parselmouth, df_lpcmeans, df_larmeans, df_cepmeans, df_mfccmeans], axis=1)\n",
    "combined_df2 = pd.concat([df_parselmouth, df_lpcvars, df_larvars, df_cepvars, df_mfccvars], axis=1)\n",
    "\n",
    "# Supprimer des colonnes en doublon\n",
    "combined_df1 = combined_df1.loc[:, ~combined_df1.columns.duplicated()]\n",
    "combined_df2 = combined_df2.loc[:, ~combined_df2.columns.duplicated()]\n",
    "\n",
    "print(combined_df1.info())\n",
    "print(combined_df2.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des classes\n",
    "sns.countplot(data=combined_df1, x='Label')\n",
    "plt.title(\"Répartition des classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution en fonction de l'âge\n",
    "sns.boxplot(data=combined_df1, x='Label', y='Age')\n",
    "plt.title(\"Distribution de l'âge en fonction de la classe\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Parkinson en fonction du MFCC_means_MFCC1 à MFCC_means_MFCC10 dans un seul graphique\n",
    "\n",
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df1, x='Label', y=f'MFCC_means_MFCC{i}')\n",
    "    plt.title(f\"Distribution de MFCC{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df1, x='Label', y=f'LAR_means_LAR{i}')\n",
    "    plt.title(f\"Distribution de LAR{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df1, x='Label', y=f'Cep_means_Cep{i}')\n",
    "    plt.title(f\"Distribution de Cep{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df1, x='Label', y=f'LPC_means_LPC{i}')\n",
    "    plt.title(f\"Distribution de LPC{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df2, x='Label', y=f'MFCC_var_MFCC{i}')\n",
    "    plt.title(f\"Distribution de MFCC{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df2, x='Label', y=f'LAR_var_LAR{i}')\n",
    "    plt.title(f\"Distribution de LAR{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df2, x='Label', y=f'LPC_var_LPC{i}')\n",
    "    plt.title(f\"Distribution de LPC{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 11):\n",
    "    sns.boxplot(data=combined_df2, x='Label', y=f'Cep_var_Cep{i}')\n",
    "    plt.title(f\"Distribution de Cep{i} en fonction de la classe\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "print(combined_df1.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encoder les variables catégorielles\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Sex: F = 0, M = 1\n",
    "combined_df1['Sex'] = encoder.fit_transform(combined_df1['Sex'])\n",
    "combined_df2['Sex'] = encoder.fit_transform(combined_df2['Sex'])\n",
    "\n",
    "# HC = 0, PD = 1\n",
    "combined_df1['Label'] = encoder.fit_transform(combined_df1['Label'])\n",
    "combined_df2['Label'] = encoder.fit_transform(combined_df2['Label'])\n",
    "\n",
    "combined_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les colonnes numériques dont Label\n",
    "numeric_df = combined_df1.select_dtypes(include='number')\n",
    "numeric_df.info()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_df.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Corrélations des caractéristiques audio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les colonnes numériques seulement\n",
    "numeric_df2 = combined_df2.select_dtypes(include=[\"number\"])\n",
    "numeric_df2.info()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_df2.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Corrélations des caractéristiques audio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpage du Jeu de Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage du JDD correctement (Train/Valid/Test) en fonction de la colonne Label pour le dataset combined_df1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = combined_df1.drop(columns=['Sample', 'Label'])\n",
    "y = combined_df1['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage du JDD correctement (Train/Valid/Test) en fonction de la colonne Label pour le dataset combined_df2\n",
    "\n",
    "X2 = combined_df2.drop(columns=['Sample', 'Label'])\n",
    "y2 = combined_df2['Label']\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, stratify=y2, random_state=42)\n",
    "X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2_train, y2_train, test_size=0.2, stratify=y2_train, random_state=42)\n",
    "\n",
    "print(X2_train.shape, X2_valid.shape, X2_test.shape)\n",
    "print(y2.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrainement des modèles de Machine Learning sur les datasets séparés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle ML simple de régression logistique sur le dataset combined_df1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle ML simple de régression logistique sur le dataset combined_df2\n",
    "model2 = LogisticRegression(max_iter=1000)\n",
    "model2.fit(X2_train, y2_train)\n",
    "y2_pred = model2.predict(X2_valid)\n",
    "\n",
    "print(accuracy_score(y2_valid, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle ML simple de random forest sur combined_df1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "print(accuracy_score(y_valid, y_pred))\n",
    "\n",
    "# Modèle ML simple de random forest sur combined_df2\n",
    "model2 = RandomForestClassifier()\n",
    "model2.fit(X2_train, y2_train)\n",
    "y2_pred = model2.predict(X2_valid)\n",
    "\n",
    "print(accuracy_score(y2_valid, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation des métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des résultats (RoC, tableau Faux positif etcs) pour le modèle de régression logistique sur le dataset combined_df1\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "y_pred_probabilite = model.predict_proba(X_valid)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_pred_probabilite)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title('Courbe ROC')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score\", roc_auc_score(y_valid, y_pred_probabilite))\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des résultats pour le modèle de régression logistique sur combined_df2\n",
    "y2_pred_probabilite = model2.predict_proba(X2_valid)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y2_valid, y2_pred_probabilite)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title('Courbe ROC')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score\", roc_auc_score(y2_valid, y2_pred_probabilite))\n",
    "print(confusion_matrix(y2_valid, y2_pred))\n",
    "print(classification_report(y2_valid, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des résultats pour le modèle de random forest sur combined_df1\n",
    "y_pred_probabilite = model.predict_proba(X_valid)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_valid, y_pred_probabilite)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title('Courbe ROC')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score\", roc_auc_score(y_valid, y_pred_probabilite))\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print(classification_report(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des résultats pour le modèle de random forest sur combined_df2\n",
    "y2_pred_probabilite = model2.predict_proba(X2_valid)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y2_valid, y2_pred_probabilite)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title('Courbe ROC')\n",
    "plt.show()\n",
    "\n",
    "print(\"ROC AUC Score\", roc_auc_score(y2_valid, y2_pred_probabilite))\n",
    "print(confusion_matrix(y2_valid, y2_pred))\n",
    "print(classification_report(y2_valid, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approche en combinant toutes les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les deux Dataframes\n",
    "combined_df = pd.concat([combined_df1, combined_df2.drop(columns=['Sample', 'Label', 'Sex'])], axis=1)\n",
    "\n",
    "# Supprimer les colonnes en doublons si nécecessité\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]\n",
    "\n",
    "# Info du Dataframe\n",
    "print(combined_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mutual_info_classif\n",
    "sklearn.feature_selection.mutual_info_classif(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None, n_jobs=None)[source]\n",
    "Estimate mutual information for a discrete target variable.\n",
    "\n",
    "Mutual information (MI) [1] between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner les colonnes numériques\n",
    "numeric_df_comb = combined_df.select_dtypes(include='number')\n",
    "numeric_df_comb.info()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_df_comb.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title(\"Corrélations des caractéristiques audio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélectionner les features les plus importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = combined_df.drop(columns=['Sample', 'Label'])\n",
    "y = combined_df['Label']\n",
    "\n",
    "# Calculer le mutual info score\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "\n",
    "# Créer un tableau pour visualiser les scores de chaque feature\n",
    "mi_tab = pd.Series(mi_scores, index=X.columns)\n",
    "mi_tab.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# 20 features les plus importantes\n",
    "top_20_mi = mi_tab.head(20)\n",
    "print(\"20 classes/features les plus importantes :\\n\", top_20_mi)\n",
    "\n",
    "# Afficher\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_20_mi.plot(kind='barh')\n",
    "plt.title(\"20 features les plus importantes avec Mutual Information Score\")\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialisation du RFC\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Importance des features\n",
    "rf_feature_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "rf_feature_importances.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "# Afficher les 20 features les plus importantes\n",
    "top_20_rf = rf_feature_importances.head(20)\n",
    "print(\"20 classes/features les plus importantes :\\n\", top_20_rf)\n",
    "print(top_20_rf.values)\n",
    "\n",
    "# Afficher\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_20_rf.plot(kind='barh')\n",
    "plt.title(\"20 features les plus importantes selon le Random Forest Feature Importance\")\n",
    "plt.xlabel(\"Score de Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les scores pour éviter qu'une méthode domine l'autre\n",
    "mi_tab_norm = mi_tab / mi_tab.max()\n",
    "rf_feature_importances_norm = rf_feature_importances / rf_feature_importances.max()\n",
    "\n",
    "# Fusionner les scores pour les features sélectionnées\n",
    "selected_features = list(set(top_20_mi.index) | set(top_20_rf.index))\n",
    "combined_scores = pd.DataFrame({\n",
    "    'MI_Score': mi_tab_norm[selected_features],\n",
    "    'RF_Score': rf_feature_importances_norm[selected_features]\n",
    "})\n",
    "\n",
    "# Calcul d'un score moyen\n",
    "combined_scores['Avg_Score'] = combined_scores.mean(axis=1)\n",
    "\n",
    "# Trier et récupérer les 20 meilleures features\n",
    "top_20_final = combined_scores.sort_values(by='Avg_Score', ascending=False).head(20)\n",
    "\n",
    "# Liste des features finales\n",
    "selected_features_final = list(top_20_final.index)\n",
    "\n",
    "# Sélectionner ces features dans le dataset\n",
    "X_selected = X[selected_features_final]\n",
    "\n",
    "print(\"20 meilleures features sélectionnées :\", selected_features_final)\n",
    "\n",
    "# Afficher les 20 meilleures features avec leur score moyen\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_20_final['Avg_Score'].plot(kind='barh')\n",
    "plt.title(\"20 meilleures features sélectionnées\")\n",
    "plt.xlabel(\"Score moyen\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpage du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage du JDD correctement\n",
    "y3 = combined_df['Label']\n",
    "\n",
    "X3_train, X3_valid, y3_train, y3_valid = train_test_split(X_selected, y3, test_size=0.3, stratify=y3, random_state=42)\n",
    "\n",
    "print(X3_train.shape, X3_valid.shape)\n",
    "print(y3.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Définition des paramètres à tester\n",
    "param_grid_rf = {'n_estimators': [50, 100, 200],'max_depth': [None, 10, 20],'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Grid Search\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_rf.fit(X_selected, y3)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "print(\"Meilleurs paramètres pour Random Forest : \", grid_search_rf.best_params_)\n",
    "best_estimators_rf = grid_search_rf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Définition des paramètres à tester pour le LR\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100],'penalty': ['l1', 'l2'],'solver': ['liblinear']} # uniquement liblinear car petit dataset et pas un probleme multiclasse\n",
    "\n",
    "# Grid search cv\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(random_state=42), param_grid_lr, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_lr.fit(X_selected, y3)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "print(\"Meilleurs paramètres pour Regression Logistique : \", grid_search_lr.best_params_)\n",
    "best_estimators_lr = grid_search_lr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat des optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  modèle avec les meilleurs paramètres trouvés\n",
    "rf_optimise = best_estimators_rf\n",
    "\n",
    "# training\n",
    "rf_optimise.fit(X3_train, y3_train)\n",
    "\n",
    "# prediction\n",
    "y_pred_rf = rf_optimise.predict(X3_valid)\n",
    "\n",
    "# evaluation\n",
    "print(\"Précision du random forest : \", accuracy_score(y3_valid, y_pred_rf))\n",
    "print(classification_report(y3_valid, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_rf = rf_optimise.predict_proba(X3_valid)[:, 1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y3_valid, y_pred_probabilite_rf)\n",
    "roc_auc = roc_auc_score(y3_valid, y_pred_probabilite_rf)\n",
    "\n",
    "plt.plot(fpr_rf, tpr_rf, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC de l'approche 2 avec Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcul de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(rf_optimise, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# modèle avec les meilleurs paramètres trouvés\n",
    "lr_optimized = best_estimators_lr\n",
    "\n",
    "# training\n",
    "lr_optimized.fit(X3_train, y3_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_lr = lr_optimized.predict(X3_valid)\n",
    "\n",
    "# valuation\n",
    "print(\"Précision de la Regression logistique :\", accuracy_score(y3_valid, y_pred_lr))\n",
    "print(classification_report(y3_valid, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_lr = lr_optimized.predict_proba(X3_valid)[:, 1]\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y3_valid, y_pred_probabilite_lr)\n",
    "roc_auc_lr = roc_auc_score(y3_valid, y_pred_probabilite_lr)\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, color='blue', label=f'ROC curve (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC de l'approche 2 avec une Regression Logistique\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(lr_optimized, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va essayer de faire toutes les combinaisons possibles manuellement\n",
    "param_grid = {'n_estimators': [50, 100, 200],'max_depth': [None, 5, 10, 20, 30],'min_samples_split': [2, 5, 10, 20],'min_samples_leaf': [1, 2, 4],'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "results = []\n",
    "\n",
    "# parcourir toutes les combinaisons de parametres\n",
    "for n_estim in param_grid['n_estimators']:\n",
    "    for max_depth in param_grid['max_depth']:\n",
    "        for min_samples_split in param_grid['min_samples_split']:\n",
    "            for min_samples_leaf in param_grid['min_samples_leaf']:\n",
    "                for max_features in param_grid['max_features']:\n",
    "                    model = RandomForestClassifier(n_estimators=n_estim,max_depth=max_depth,min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf,max_features=max_features,random_state=42)\n",
    "                    \n",
    "                    # Entrainement du modele\n",
    "                    model.fit(X3_train, y3_train)\n",
    "                    \n",
    "                    # predictions sur validation set\n",
    "                    y_pred = model.predict(X3_valid)\n",
    "                    \n",
    "                    # accuracy score\n",
    "                    accuracy = accuracy_score(y3_valid, y_pred)\n",
    "                    \n",
    "                    # ajouter les resultats à la liste results\n",
    "                    results.append({'n_estimators': n_estim,'max_depth': max_depth,'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'max_features': max_features,'accuracy': accuracy})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Resultats triés par accuracy\n",
    "results_df_trie = results_df.sort_values(by='accuracy', ascending=False)\n",
    "print(results_df_trie)\n",
    "\n",
    "# Afficher la meilleure combinaison\n",
    "best_combination = results_df_trie.iloc[0]\n",
    "print(\"\\n\\nMeilleure combinaison de paramètres pour le random forest: \")\n",
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement du meilleur modèle de RF\n",
    "best_rf_modele = RandomForestClassifier(n_estimators=int(best_combination['n_estimators']),max_depth=int(best_combination['max_depth']),min_samples_split=int(best_combination['min_samples_split']),min_samples_leaf=int(best_combination['min_samples_leaf']),max_features=best_combination['max_features'],random_state=42)\n",
    "\n",
    "best_rf_modele.fit(X3_train, y3_train)\n",
    "y_pred_best_rf = best_rf_modele.predict(X3_valid)\n",
    "\n",
    "print(\"Accuracy score du meilleure modèle de RF : \", accuracy_score(y3_valid, y_pred_best_rf))\n",
    "print(classification_report(y3_valid, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_best_rf = best_rf_modele.predict_proba(X3_valid)[:, 1]\n",
    "fpr_best_rf, tpr_best_rf, thresholds_best_rf = roc_curve(y3_valid, y_pred_probabilite_best_rf)\n",
    "roc_auc_best_rf = roc_auc_score(y3_valid, y_pred_probabilite_best_rf)\n",
    "\n",
    "plt.plot(fpr_best_rf, tpr_best_rf, color='blue', label=f'ROC curve (AUC = {roc_auc_best_rf:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC du meilleur modèle de Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_rf_modele, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairie sci-kit optimize pour utiliser la fonction BayesSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "search_spaces_bayes_rf = {'n_estimators': Integer(50, 200),'max_depth': Integer(5, 50),'min_samples_split': Integer(2, 20),'min_samples_leaf': Integer(1, 10),'max_features': Categorical(['sqrt', 'log2'])}\n",
    "\n",
    "# BayesSearchCV\n",
    "bayes_search_rf = BayesSearchCV(RandomForestClassifier(random_state=42), search_spaces_bayes_rf, n_iter=50, cv=5, scoring='accuracy')\n",
    "\n",
    "# Entrainement\n",
    "bayes_search_rf.fit(X3_train, y3_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "print(\"Meilleurs paramètres pour Random Forest avec BayesSearchCV : \", bayes_search_rf.best_params_)\n",
    "best_rf_bayes = bayes_search_rf.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_rf_bayes = best_rf_bayes.predict(X3_valid)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Précision du random forest avec BayesSearchCV : \", accuracy_score(y3_valid, y_pred_rf_bayes))\n",
    "print(classification_report(y3_valid, y_pred_rf_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_rf_bayes = best_rf_bayes.predict_proba(X3_valid)[:, 1]\n",
    "fpr_rf_bayes, tpr_rf_bayes, thresholds_rf_bayes = roc_curve(y3_valid, y_pred_probabilite_rf_bayes)\n",
    "roc_auc_rf_bayes = roc_auc_score(y3_valid, y_pred_probabilite_rf_bayes)\n",
    "\n",
    "plt.plot(fpr_rf_bayes, tpr_rf_bayes, color='blue', label=f'ROC curve (AUC = {roc_auc_rf_bayes:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC de l'approche 2 avec une recherche Bayesienne pour le Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_rf_bayes, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_combination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rencontre une erreur a cause de la version de scikit learn. On va entrainer manuellement xgb comme pour random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# grille de paramètres pour XGBoost\n",
    "param_grid_xgb = {'n_estimators': [200, 300, 400],'max_depth': [10, 20, 30],'learning_rate': [0.01, 0.1, 0.3],'subsample': [0.5, 0.7, 1],'colsample_bytree': [0.5, 0.7, 1]}\n",
    "\n",
    "results_xgb = []\n",
    "\n",
    "# Parcourir toutes les combinaisons de parametres xgboost\n",
    "for n_estimators in param_grid_xgb['n_estimators']:\n",
    "    for max_depth in param_grid_xgb['max_depth']:\n",
    "        for learning_rate in param_grid_xgb['learning_rate']:\n",
    "            for subsample in param_grid_xgb['subsample']:\n",
    "                for colsample_bytree in param_grid_xgb['colsample_bytree']:\n",
    "                    \n",
    "                    # Initialiser le model\n",
    "                    model = XGBClassifier(n_estimators=n_estimators,max_depth=max_depth,learning_rate=learning_rate,subsample=subsample,colsample_bytree=colsample_bytree,random_state=42)\n",
    "                    \n",
    "                    # Entrainement\n",
    "                    model.fit(X3_train, y3_train)\n",
    "                    \n",
    "                    # Predictions sur le validation set\n",
    "                    y_pred = model.predict(X3_valid)\n",
    "                    \n",
    "                    # Accuracy score\n",
    "                    accuracy = accuracy_score(y3_valid, y_pred)\n",
    "                    \n",
    "                    # Stocker les resultats dans la liste results_xgb\n",
    "                    results_xgb.append({'n_estimators': n_estimators,'max_depth': max_depth,'learning_rate': learning_rate,'subsample': subsample,'colsample_bytree': colsample_bytree,'accuracy': accuracy})\n",
    "\n",
    "results_xgb_df = pd.DataFrame(results_xgb)\n",
    "\n",
    "# résultats triés par accuracy\n",
    "results_xgb_df_trie = results_xgb_df.sort_values(by='accuracy', ascending=False)\n",
    "print(results_xgb_df_trie)\n",
    "\n",
    "# meilleure combinaison\n",
    "best_combination_xgb = results_xgb_df_trie.iloc[0]\n",
    "print(\"\\nMeilleure combinaison de paramètres pour XGBoost :\")\n",
    "print(best_combination_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation du modele avec la meilleure combinaison\n",
    "best_xgb_model = XGBClassifier(n_estimators=int(best_combination_xgb['n_estimators']),max_depth=int(best_combination_xgb['max_depth']),learning_rate=best_combination_xgb['learning_rate'],subsample=best_combination_xgb['subsample'],colsample_bytree=best_combination_xgb['colsample_bytree'],random_state=42)\n",
    "\n",
    "# Entrainement\n",
    "best_xgb_model.fit(X3_train, y3_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred_xgb = best_xgb_model.predict(X3_valid)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy de XGBoost : \", accuracy_score(y3_valid, y_pred_xgb))\n",
    "print(\"Classification Report :\\n\", classification_report(y3_valid, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_xgb = best_xgb_model.predict_proba(X3_valid)[:, 1]\n",
    "fpr_xgb, tpr_xgb, thresholds_xgb = roc_curve(y3_valid, y_pred_probabilite_xgb)\n",
    "roc_auc_xgb = roc_auc_score(y3_valid, y_pred_probabilite_xgb)\n",
    "\n",
    "plt.plot(fpr_xgb, tpr_xgb, color='blue', label=f'ROC curve (AUC = {roc_auc_xgb:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC de l'approche 2 avec XGBoost\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_xgb_model, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# grille de paramètres pour LightGBM\n",
    "param_grid_lgb = {'n_estimators': [100, 200, 300],'max_depth': [3, 5, 7],'learning_rate': [0.01, 0.1, 0.2],'subsample': [0.8, 0.9, 1.0],'colsample_bytree': [0.8, 0.9, 1.0]}\n",
    "\n",
    "# GridSearchCV pour LightGBM\n",
    "grid_search_lgb = GridSearchCV(LGBMClassifier(random_state=42),param_grid_lgb,cv=5,scoring='accuracy',n_jobs=-1)\n",
    "\n",
    "# Entrainement\n",
    "grid_search_lgb.fit(X3_train, y3_train)\n",
    "\n",
    "# Meilleurs parametres\n",
    "print(\"Meilleurs paramètres pour LightGBM : \", grid_search_lgb.best_params_)\n",
    "best_lgb = grid_search_lgb.best_estimator_\n",
    "\n",
    "# Prediction\n",
    "y_pred_lgb = best_lgb.predict(X3_valid)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy SCORE de LightGBM : \", accuracy_score(y3_valid, y_pred_lgb))\n",
    "print(\"Classification Report :\\n\", classification_report(y3_valid, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe ROC avec AUC\n",
    "y_pred_probabilite_lgb = best_lgb.predict_proba(X3_valid)[:, 1]\n",
    "fpr_lgb, tpr_lgb, thresholds_lgb = roc_curve(y3_valid, y_pred_probabilite_lgb)\n",
    "roc_auc_lgb = roc_auc_score(y3_valid, y_pred_probabilite_lgb)\n",
    "\n",
    "plt.plot(fpr_lgb, tpr_lgb, color='blue', label=f'ROC curve (AUC = {roc_auc_lgb:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('Taux de Faux Positif')\n",
    "plt.ylabel('Taux de Vrai Positif')\n",
    "plt.title(\"Courbe ROC de l'approche 2 avec LightGBM\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot de la matrice de confusion\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_lgb, X3_valid, y3_valid, display_labels=['HC', 'PD'])\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapley Additive Explanations (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# Expliquer le modèle Random Forest\n",
    "explainer = shap.TreeExplainer(best_rf_modele)\n",
    "\n",
    "# Calculer les valeurs SHAP pour l'ensemble d'entraînement\n",
    "shap_values = explainer.shap_values(X3_train)\n",
    "\n",
    "# Vérifier la structure de shap_values\n",
    "print(\"Shape de shap_values :\", np.array(shap_values).shape) \n",
    "\n",
    "# Extraire les valeurs SHAP pour la classe 1\n",
    "shap_values_class1 = np.array([shap_values[i][:, 1] for i in range(len(shap_values))])\n",
    "\n",
    "# Vérifier les dimensions de shap_values_class1\n",
    "print(\"Shape de shap_values_class1 :\", shap_values_class1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'importance des features pour la classe 1\n",
    "shap.summary_plot(shap_values_class1, X3_train, plot_type=\"bar\")\n",
    "\n",
    "# Visualiser l'impact des features sur une prédiction individuelle (classe 1)\n",
    "shap.initjs()\n",
    "\n",
    "# Choisir une instance spécifique\n",
    "instance_index = 0\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],  # Valeur attendue pour la classe 1\n",
    "    shap_values_class1[instance_index, :],  # Valeurs SHAP pour la classe 1\n",
    "    X3_train.iloc[instance_index, :],  # Features de l'instance\n",
    "    matplotlib=True  # Afficher dans un notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
