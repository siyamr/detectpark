{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche Signal pour Parkinson\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Chemins des dossiers\n",
    "path_to_hc = 'HC_AH/'\n",
    "path_to_pd = 'PD_AH/'\n",
    "\n",
    "# Fonction pour charger les fichiers audio\n",
    "def charger_audio_files(fichier):\n",
    "    signals = []\n",
    "    for file in os.listdir(fichier):\n",
    "        if file.endswith('.wav'):\n",
    "            audio_path = os.path.join(fichier, file)\n",
    "            y, sr = librosa.load(audio_path, sr=None)  \n",
    "            signals.append(y)\n",
    "    return signals\n",
    "\n",
    "# Charger les fichiers audio en utilisant la fonction\n",
    "hc_signals = charger_audio_files(path_to_hc)\n",
    "pd_signals = charger_audio_files(path_to_pd)\n",
    "\n",
    "# Combiner les données\n",
    "X = hc_signals + pd_signals  # Liste des signaux audio\n",
    "y = np.array([0] * len(hc_signals) + [1] * len(pd_signals))  # Labels (0 sain, 1 parkinsonien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de signaux audio:', len(X))\n",
    "print('Nombre de labels:', len(y))\n",
    "\n",
    "print('Exemple de signal audio:', X[0])\n",
    "print('Exemple de label:', y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une longueur commune pour tous les signaux\n",
    "fixed_length = 8000 * 3  # 3 secondes à 8000Hz = 24000 échantillons\n",
    "\n",
    "# Fonction pour redimensionner les signaux\n",
    "def fix_signal_length(signal, fixed_length):\n",
    "    if len(signal) > fixed_length:\n",
    "        signal = signal[:fixed_length]  # Tronquer selon longueur fixée\n",
    "    else:\n",
    "        signal = np.pad(signal, (0, max(0, fixed_length - len(signal))))  # Remplir avec des zéros si la longueur est inférieure\n",
    "    return signal\n",
    "\n",
    "# Appliquer la fonction à tous les signaux\n",
    "X_fixed = [fix_signal_length(signal, fixed_length) for signal in X]\n",
    "X_fixed = np.array(X_fixed)  # Convertir en tableau NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fixed, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Vérifier les formes\n",
    "print(\"Shape de X_train :\", X_train.shape)\n",
    "print(\"Shape de X_val :\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fonction pour extraire les MFCC\n",
    "def extract_mfcc(signals, sr=8000, n_mfcc=13):\n",
    "    mfccs = []\n",
    "    for signal in signals:\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfccs.append(np.mean(mfcc.T, axis=0))  # Moyenne des MFCC pour chaque signal\n",
    "    return np.array(mfccs)\n",
    "\n",
    "# Extraire les MFCC pour les ensembles d'entraînement et de validation\n",
    "X_train_mfcc = extract_mfcc(X_train)\n",
    "X_val_mfcc = extract_mfcc(X_val)\n",
    "\n",
    "# Entraîner un SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_mfcc, y_train)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred_svm = svm_model.predict(X_val_mfcc)\n",
    "\n",
    "# Évaluer le modèle\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(\"Accuracy du SVM :\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Redimensionner les données pour le CNN\n",
    "X_train_cnn = X_train[..., np.newaxis]  # Ajouter une dimension pour les canaux\n",
    "X_val_cnn = X_val[..., np.newaxis]\n",
    "\n",
    "# Définir l'architecture du CNN\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(fixed_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    X_train_cnn, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_cnn, y_val)\n",
    ")\n",
    "\n",
    "# Évaluer le modèle\n",
    "test_loss, test_accuracy = model.evaluate(X_val_cnn, y_val)\n",
    "print(\"Accuracy du CNN :\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle CNN appliqué sur les spectrogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Convertir les signaux en spectrogrammes\n",
    "def audio_to_spectrogram(signal, sr=8000, n_mels=128):\n",
    "    S = librosa.feature.melspectrogram(y=signal, sr=sr, n_mels=n_mels)\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_db\n",
    "\n",
    "# Appliquer à tous les signaux\n",
    "X_train_spec = np.array([audio_to_spectrogram(signal) for signal in X_train])\n",
    "X_val_spec = np.array([audio_to_spectrogram(signal) for signal in X_val])\n",
    "\n",
    "# Redimensionner pour le CNN\n",
    "X_train_spec = X_train_spec[..., np.newaxis]\n",
    "X_val_spec = X_val_spec[..., np.newaxis]\n",
    "\n",
    "# Adapter le CNN pour les spectrogrammes\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=X_train_spec.shape[1:]),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiler et entraîner le modèle\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_spec, y_train, epochs=50, batch_size=32, validation_data=(X_val_spec, y_val))\n",
    "\n",
    "# Évaluer le modèle\n",
    "test_loss, test_accuracy = model.evaluate(X_val_spec, y_val)\n",
    "print(\"Accuracy du CNN avec spectrogrammes :\", test_accuracy)\n",
    "\n",
    "# Afficher le plot de l'accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle YAMNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "# Charger YAMNet\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "# Extraire les embeddings\n",
    "def extract_embeddings(signals):\n",
    "    embeddings = []\n",
    "    for signal in signals:\n",
    "        _, embedding, _ = model(signal)\n",
    "        embeddings.append(np.mean(embedding, axis=0))  # Moyenne sur les frames\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Appliquer à vos données\n",
    "X_train_emb = extract_embeddings(X_train)\n",
    "X_val_emb = extract_embeddings(X_val)\n",
    "\n",
    "# Entraîner un SVM sur les embeddings\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_emb, y_train)\n",
    "y_pred_svm = svm_model.predict(X_val_emb)\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(\"Accuracy du SVM avec YAMNet :\", accuracy_svm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
